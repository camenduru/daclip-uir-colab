{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/daclip-uir-colab/blob/main/daclip_uir_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/daclip-uir\n",
        "%cd /content/daclip-uir\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/daclip-uir/resolve/main/daclip_ViT-B-32-2023-09_b768x4_lr3e-5_e50_zeroadd.pt -d /content/daclip-uir/pretrained -o daclip_ViT-B-32-2023-09_b768x4_lr3e-5_e50_zeroadd.pt\n",
        "\n",
        "!pip install -q einops ema-pytorch ftfy lmdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/daclip-uir/universal-image-restoration\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import open_clip\n",
        "\n",
        "checkpoint = '/content/daclip-uir/daclip_ViT-B-32-2023-09_b768x4_lr3e-5_e50_zeroadd.pt'\n",
        "model, preprocess = open_clip.create_model_from_pretrained('daclip_ViT-B-32', pretrained=checkpoint)\n",
        "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
        "\n",
        "image = preprocess(Image.open(\"/content/test.jpg\")).unsqueeze(0)\n",
        "degradations = ['motion-blurry','hazy','jpeg-compressed','low-light','noisy','raindrop','rainy','shadowed','snowy','uncompleted']\n",
        "text = tokenizer(degradations)\n",
        "\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    text_features = model.encode_text(text)\n",
        "    image_features, degra_features = model.encode_image(image, control=True)\n",
        "    degra_features /= degra_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    text_probs = (100.0 * degra_features @ text_features.T).softmax(dim=-1)\n",
        "    index = torch.argmax(text_probs[0])\n",
        "\n",
        "print(f\"Task: {degradations[index]} - {text_probs[0][index]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
